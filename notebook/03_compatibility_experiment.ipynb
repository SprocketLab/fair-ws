{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6aa1297",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sys.path.append('../')\n",
    "sys.path.append('../../')\n",
    "from fairlearn.reductions import ExponentiatedGradient, DemographicParity, EqualizedOdds\n",
    "from fairlearn.postprocessing import ThresholdOptimizer\n",
    "from fairlearn.preprocessing import CorrelationRemover\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# custom\n",
    "from fairws.data_util import load_dataset, load_LIFT_embedding, load_LF\n",
    "from fairws.metrics import exp_eval\n",
    "from fairws.sbm import get_baseline_pseudolabel, get_sbm_pseudolabel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ac78da",
   "metadata": {},
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4217ea0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"hateXplain\" # adult | bank_marketing | CivilComments | hateXplain | CelebA | UTKFace\n",
    "use_LIFT_embedding = False # only for adult, bank_marketing\n",
    "sbm_diff_threshold = 0.05\n",
    "fairml_method = \"optimal_threshold\" # correlation_remover | exponetiated_gradeint | optimal_threshold\n",
    "\n",
    "result_collection = pd.DataFrame() # to keep results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df53bbf",
   "metadata": {},
   "source": [
    "# WS baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91e0c6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 1000/1000 [00:02<00:00, 464.88epoch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'condition': 'ws_baseline', 'accuracy': 0.5491931285788652, 'fscore': 0.5563524590163934, 'precision': 0.6687192118226601, 'recall': 0.4763157894736842, 'demographic_parity_gap': 0.02021467685699463, 'equal_opportunity_gap': 0.03451120853424072, 'fairml_method': 'optimal_threshold'}\n"
     ]
    }
   ],
   "source": [
    "cond = \"ws_baseline\"\n",
    "\n",
    "x_train, y_train, a_train, x_test, y_test, a_test = load_dataset(dataset_name=dataset_name,\n",
    "                                                                    data_base_path='../data')\n",
    "\n",
    "# weak supervision\n",
    "L = load_LF(dataset_name, data_base_path='../data')\n",
    "y_train = get_baseline_pseudolabel(L)\n",
    "\n",
    "# downstream task\n",
    "model = LogisticRegression()\n",
    "\n",
    "# fair ml method\n",
    "if fairml_method == \"correlation_remover\":\n",
    "    x = np.concatenate([x_train, x_test], axis=0)\n",
    "    a = np.concatenate([a_train, a_test], axis=0)\n",
    "    x_aug = np.concatenate([x, np.expand_dims(a, axis=1)], axis=1)\n",
    "    decorr = CorrelationRemover(sensitive_feature_ids=[x_train.shape[1]], alpha=1)\n",
    "    x_decorr = decorr.fit_transform(x_aug)\n",
    "    x_train_decorr = x_decorr[:x_train.shape[0]]\n",
    "    x_test_decorr = x_decorr[x_train.shape[0]:]\n",
    "    model.fit(x_train_decorr, y_train)\n",
    "    y_pred = model.predict(x_test_decorr)\n",
    "elif fairml_method == \"exponentiated_gradient\":\n",
    "    constraints = DemographicParity(difference_bound=0)\n",
    "    exp_grad_est = ExponentiatedGradient(\n",
    "    estimator=model,\n",
    "    constraints=constraints,\n",
    "    )\n",
    "    exp_grad_est.fit(x_train, y_train, sensitive_features=a_train)\n",
    "    y_pred = exp_grad_est.predict(x_test)\n",
    "elif fairml_method == \"optimal_threshold\":\n",
    "    thr_opt_est = ThresholdOptimizer(\n",
    "    estimator=model,\n",
    "    constraints='demographic_parity',\n",
    "    objective='accuracy_score',\n",
    "    )\n",
    "    thr_opt_est.fit(x_train, y_train, sensitive_features=a_train)\n",
    "    y_pred = thr_opt_est.predict(x_test, sensitive_features=a_test)\n",
    "else:\n",
    "    print(\"fairml_method\", fairml_method, \"not implemented.\")\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "            \n",
    "result = exp_eval(y_test, y_pred, a_test, cond=cond)\n",
    "result['fairml_method'] = fairml_method\n",
    "print(result)\n",
    "\n",
    "result_collection = result_collection.append(result, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c1a4af",
   "metadata": {},
   "source": [
    "# SBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1932c365",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 1000/1000 [00:02<00:00, 467.34epoch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'condition': 'sbm(None)', 'accuracy': 0.5866736074960958, 'fscore': 0.6583476764199656, 'precision': 0.6461148648648649, 'recall': 0.6710526315789473, 'demographic_parity_gap': 0.018130362033843994, 'equal_opportunity_gap': 0.0042018890380859375, 'fairml_method': 'optimal_threshold'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 1000/1000 [00:02<00:00, 469.71epoch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'condition': 'sbm(linear)', 'accuracy': 0.6007287870900573, 'fscore': 0.6852687730816578, 'precision': 0.643793369313801, 'recall': 0.7324561403508771, 'demographic_parity_gap': 0.006840825080871582, 'equal_opportunity_gap': 0.009219586849212646, 'fairml_method': 'optimal_threshold'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 1000/1000 [00:02<00:00, 482.04epoch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'condition': 'sbm(sinkhorn)', 'accuracy': 0.6048932847475273, 'fscore': 0.6908350305498981, 'precision': 0.6448669201520912, 'recall': 0.743859649122807, 'demographic_parity_gap': 0.0027193427085876465, 'equal_opportunity_gap': 0.025291621685028076, 'fairml_method': 'optimal_threshold'}\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, a_train, x_test, y_test, a_test = load_dataset(dataset_name=dataset_name,\n",
    "                                                                    data_base_path='../data')\n",
    "\n",
    "for ot_type in [None, \"linear\", \"sinkhorn\"]:\n",
    "    cond = f\"sbm({ot_type})\"\n",
    "\n",
    "    L = load_LF(dataset_name, data_base_path='../data')\n",
    "    if use_LIFT_embedding:\n",
    "        x_embedding_train, x_embedding_test = load_LIFT_embedding(dataset_name=dataset_name,\n",
    "                                                                    data_base_path='../data')\n",
    "        y_train= get_sbm_pseudolabel(L, x_embedding_train, a_train, dataset_name, \n",
    "                                     ot_type=ot_type, diff_threshold=sbm_diff_threshold,\n",
    "                                     use_LIFT_embedding=True)\n",
    "        \n",
    "    else:\n",
    "        y_train= get_sbm_pseudolabel(L, x_train, a_train, dataset_name, \n",
    "                                     ot_type=ot_type, diff_threshold=sbm_diff_threshold)\n",
    "    \n",
    "    # downstream task\n",
    "    model = LogisticRegression()\n",
    "    \n",
    "    # fair ml method\n",
    "    if fairml_method == \"correlation_remover\":\n",
    "        x = np.concatenate([x_train, x_test], axis=0)\n",
    "        a = np.concatenate([a_train, a_test], axis=0)\n",
    "        x_aug = np.concatenate([x, np.expand_dims(a, axis=1)], axis=1)\n",
    "        decorr = CorrelationRemover(sensitive_feature_ids=[x_train.shape[1]], alpha=1)\n",
    "        x_decorr = decorr.fit_transform(x_aug)\n",
    "        x_train_decorr = x_decorr[:x_train.shape[0]]\n",
    "        x_test_decorr = x_decorr[x_train.shape[0]:]\n",
    "        model.fit(x_train_decorr, y_train)\n",
    "        y_pred = model.predict(x_test_decorr)\n",
    "    elif fairml_method == \"exponentiated_gradient\":\n",
    "        constraints = DemographicParity(difference_bound=0)\n",
    "        exp_grad_est = ExponentiatedGradient(\n",
    "        estimator=model,\n",
    "        constraints=constraints,\n",
    "        )\n",
    "        exp_grad_est.fit(x_train, y_train, sensitive_features=a_train)\n",
    "        y_pred = exp_grad_est.predict(x_test)\n",
    "    elif fairml_method == \"optimal_threshold\":\n",
    "        thr_opt_est = ThresholdOptimizer(\n",
    "        estimator=model,\n",
    "        constraints='demographic_parity',\n",
    "        objective='accuracy_score',\n",
    "        )\n",
    "        thr_opt_est.fit(x_train, y_train, sensitive_features=a_train)\n",
    "        y_pred = thr_opt_est.predict(x_test, sensitive_features=a_test)\n",
    "    else:\n",
    "        print(\"fairml_method\", fairml_method, \"not implemented.\")\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "\n",
    "    result = exp_eval(y_test, y_pred, a_test, cond=cond)\n",
    "    result['fairml_method'] = fairml_method\n",
    "    print(result)\n",
    "    result_collection = result_collection.append(result, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec9e08e",
   "metadata": {},
   "source": [
    "# Result summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c84579b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>condition</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>fscore</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>demographic_parity_gap</th>\n",
       "      <th>equal_opportunity_gap</th>\n",
       "      <th>fairml_method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ws_baseline</td>\n",
       "      <td>0.549193</td>\n",
       "      <td>0.556352</td>\n",
       "      <td>0.668719</td>\n",
       "      <td>0.476316</td>\n",
       "      <td>0.020215</td>\n",
       "      <td>0.034511</td>\n",
       "      <td>optimal_threshold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sbm(None)</td>\n",
       "      <td>0.586674</td>\n",
       "      <td>0.658348</td>\n",
       "      <td>0.646115</td>\n",
       "      <td>0.671053</td>\n",
       "      <td>0.018130</td>\n",
       "      <td>0.004202</td>\n",
       "      <td>optimal_threshold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sbm(linear)</td>\n",
       "      <td>0.600729</td>\n",
       "      <td>0.685269</td>\n",
       "      <td>0.643793</td>\n",
       "      <td>0.732456</td>\n",
       "      <td>0.006841</td>\n",
       "      <td>0.009220</td>\n",
       "      <td>optimal_threshold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sbm(sinkhorn)</td>\n",
       "      <td>0.604893</td>\n",
       "      <td>0.690835</td>\n",
       "      <td>0.644867</td>\n",
       "      <td>0.743860</td>\n",
       "      <td>0.002719</td>\n",
       "      <td>0.025292</td>\n",
       "      <td>optimal_threshold</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       condition  accuracy    fscore  precision    recall  \\\n",
       "0    ws_baseline  0.549193  0.556352   0.668719  0.476316   \n",
       "1      sbm(None)  0.586674  0.658348   0.646115  0.671053   \n",
       "2    sbm(linear)  0.600729  0.685269   0.643793  0.732456   \n",
       "3  sbm(sinkhorn)  0.604893  0.690835   0.644867  0.743860   \n",
       "\n",
       "   demographic_parity_gap  equal_opportunity_gap      fairml_method  \n",
       "0                0.020215               0.034511  optimal_threshold  \n",
       "1                0.018130               0.004202  optimal_threshold  \n",
       "2                0.006841               0.009220  optimal_threshold  \n",
       "3                0.002719               0.025292  optimal_threshold  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_collection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
