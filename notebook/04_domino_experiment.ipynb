{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6aa1297",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sys.path.append('../')\n",
    "sys.path.append('../../')\n",
    "\n",
    "from domino import DominoSlicer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from hyperlm import HyperLabelModel as LabelModel\n",
    "\n",
    "from fairws.data_util import load_wrench_dataset, load_LF\n",
    "from fairws.metrics import exp_eval\n",
    "from fairws.sbm import get_baseline_pseudolabel, get_sbm_pseudolabel, find_sbm_mapping, correct_bias\n",
    "from fairws.data_util import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dde7431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper LM\n",
    "lm = LabelModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ac78da",
   "metadata": {},
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4217ea0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_base_path = '../data'\n",
    "dataset_name = \"census\"\n",
    "use_LIFT_embedding = False # only for adult, bank_marketing\n",
    "sbm_diff_threshold = 0.05\n",
    "\n",
    "result_collection = pd.DataFrame() # to keep results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48aaf981",
   "metadata": {},
   "source": [
    "# Fully supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28fb8d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'condition': 'fs', 'accuracy': 0.8456483017013697, 'fscore': 0.6341534430048041, 'precision': 0.7204763479986768, 'recall': 0.5663026521060842}\n"
     ]
    }
   ],
   "source": [
    "cond = \"fs\"\n",
    "x_train, y_train, x_test, y_test = load_wrench_dataset(dataset_name=dataset_name,\n",
    "                                                       data_base_path='../data')\n",
    "model = LogisticRegression()\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "result = exp_eval(y_test, y_pred, cond=cond, fairness=False)\n",
    "print(result)\n",
    "\n",
    "result_collection = result_collection.append(result, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df53bbf",
   "metadata": {},
   "source": [
    "# WS baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91e0c6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'condition': 'ws_baseline', 'accuracy': 0.7998894416804865, 'fscore': 0.5506206896551723, 'precision': 0.5863689776733255, 'recall': 0.5189807592303692}\n"
     ]
    }
   ],
   "source": [
    "cond = \"ws_baseline\"\n",
    "\n",
    "x_train, y_train, x_test, y_test = load_wrench_dataset(dataset_name=dataset_name,\n",
    "                                                       data_base_path='../data')\n",
    "# weak supervision\n",
    "L = load_LF(dataset_name, data_base_path='../data')\n",
    "y_train = lm.infer(L)\n",
    "# y_train = get_baseline_pseudolabel(L)\n",
    "\n",
    "# downstream task\n",
    "model = LogisticRegression()\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "result = exp_eval(y_test, y_pred, cond=cond, fairness=False)\n",
    "print(result)\n",
    "\n",
    "result_collection = result_collection.append(result, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c1a4af",
   "metadata": {},
   "source": [
    "# Domino + SBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1932c365",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|\u001b[38;2;241;122;74m██▏       \u001b[0m| 22/100 [00:00<00:01, 57.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'condition': 'sbm(None)', 'accuracy': 0.8005036545666728, 'fscore': 0.5636754433100484, 'precision': 0.5831017231795442, 'recall': 0.5455018200728029}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|\u001b[38;2;241;122;74m████      \u001b[0m| 41/100 [00:00<00:01, 54.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'condition': 'sbm(linear)', 'accuracy': 0.7981696455991647, 'fscore': 0.5417015341701534, 'precision': 0.5842358604091457, 'recall': 0.5049401976079043}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|\u001b[38;2;241;122;74m█████▏    \u001b[0m| 52/100 [00:00<00:00, 55.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'condition': 'sbm(sinkhorn)', 'accuracy': 0.8067686260057736, 'fscore': 0.5788487282463185, 'precision': 0.5965783664459161, 'recall': 0.5621424856994279}\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test = load_wrench_dataset(dataset_name=dataset_name,\n",
    "                                                       data_base_path='../data')\n",
    "for ot_type in [None, \"linear\", \"sinkhorn\"]:\n",
    "    cond = f\"sbm({ot_type})\"\n",
    "\n",
    "    L = load_LF(dataset_name, data_base_path='../data')\n",
    "    \n",
    "    y_pseudo_train = lm.infer(L)\n",
    "    y_train_proba = lm.infer(L, return_probs=True)\n",
    "    slicer = DominoSlicer(n_slices=2, n_pca_components=min(x_train.shape[1], 128))\n",
    "    slicer.fit(embeddings=x_train, targets=y_pseudo_train, pred_probs=y_train_proba)\n",
    "    a_train = slicer.predict(\n",
    "        data={'embedding':x_train, 'target':y_pseudo_train, 'pred_probs':y_train_proba},\n",
    "            embeddings='embedding'\n",
    "        )[:, 1]\n",
    "    \n",
    "    # apply sbm\n",
    "    sbm_mapping = find_sbm_mapping(x_train, a_train, ot_type)\n",
    "    L = correct_bias(L, a_train, sbm_mapping, sbm_diff_threshold)       \n",
    "    y_train = lm.infer(L)\n",
    "    \n",
    "    # downstream task\n",
    "    model = LogisticRegression()\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    result = exp_eval(y_test, y_pred, cond=cond, fairness=False)\n",
    "    print(result)\n",
    "    result_collection = result_collection.append(result, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec9e08e",
   "metadata": {},
   "source": [
    "# Result summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c84579b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>condition</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>fscore</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fs</td>\n",
       "      <td>0.845648</td>\n",
       "      <td>0.634153</td>\n",
       "      <td>0.720476</td>\n",
       "      <td>0.566303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ws_baseline</td>\n",
       "      <td>0.799889</td>\n",
       "      <td>0.550621</td>\n",
       "      <td>0.586369</td>\n",
       "      <td>0.518981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sbm(None)</td>\n",
       "      <td>0.800504</td>\n",
       "      <td>0.563675</td>\n",
       "      <td>0.583102</td>\n",
       "      <td>0.545502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sbm(linear)</td>\n",
       "      <td>0.798170</td>\n",
       "      <td>0.541702</td>\n",
       "      <td>0.584236</td>\n",
       "      <td>0.504940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sbm(sinkhorn)</td>\n",
       "      <td>0.806769</td>\n",
       "      <td>0.578849</td>\n",
       "      <td>0.596578</td>\n",
       "      <td>0.562142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       condition  accuracy    fscore  precision    recall\n",
       "0             fs  0.845648  0.634153   0.720476  0.566303\n",
       "1    ws_baseline  0.799889  0.550621   0.586369  0.518981\n",
       "2      sbm(None)  0.800504  0.563675   0.583102  0.545502\n",
       "3    sbm(linear)  0.798170  0.541702   0.584236  0.504940\n",
       "4  sbm(sinkhorn)  0.806769  0.578849   0.596578  0.562142"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_collection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fair-ws",
   "language": "python",
   "name": "fair-ws"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
